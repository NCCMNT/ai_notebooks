{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1abe0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.evaluation import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8974f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    p = counts / counts.sum()\n",
    "    return -np.sum(p * np.log2(p + 1e-12))   # add epsilon for numerical safety\n",
    "\n",
    "def split_dataset(X, y, feature, threshold):\n",
    "    left_mask  = X[:, feature] <= threshold\n",
    "    right_mask = X[:, feature] > threshold\n",
    "\n",
    "    return X[left_mask], y[left_mask], X[right_mask], y[right_mask]\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth = 5, min_samples_split = 2, feature_subsample_size=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.feature_subsample_size = feature_subsample_size\n",
    "        self.root = None\n",
    "\n",
    "    class Node:\n",
    "        def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "            self.feature = feature\n",
    "            self.threshold = threshold\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.value = value  # used for leaf nodes\n",
    "\n",
    "    def __most_common_label(self, y):\n",
    "        values, counts = np.unique(y, return_counts=True)\n",
    "        return values[np.argmax(counts)]\n",
    "\n",
    "    def __best_split(self, X, y):\n",
    "        best_feature, best_threshold = None, None\n",
    "        best_info_gain = -1\n",
    "\n",
    "        current_entropy = entropy(y)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        if self.feature_subsample_size:\n",
    "            feature_indices = np.random.choice(\n",
    "                n_features,\n",
    "                self.feature_subsample_size,\n",
    "                replace=False\n",
    "            )\n",
    "        else:\n",
    "            feature_indices = range(n_features)\n",
    "\n",
    "        for feature in feature_indices:\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                _, y_left, _, y_right = split_dataset(X, y, feature, threshold)\n",
    "\n",
    "                if len(y_left) == 0 or len(y_right) == 0: continue\n",
    "\n",
    "                left_entropy = entropy(y_left)\n",
    "                right_entropy = entropy(y_right)\n",
    "\n",
    "                child_entropy = (\n",
    "                    len(y_left)/n_samples * left_entropy +\n",
    "                    len(y_right)/n_samples * right_entropy\n",
    "                )\n",
    "\n",
    "                info_gain = current_entropy - child_entropy\n",
    "\n",
    "                if info_gain > best_info_gain:\n",
    "                    best_info_gain = info_gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold, best_info_gain\n",
    "    \n",
    "    def __build_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        num_classes = len(np.unique(y))\n",
    "\n",
    "        if ((self.max_depth is not None and depth >= self.max_depth) or n_samples < self.min_samples_split or num_classes == 1):\n",
    "            leaf_value = self.__most_common_label(y)\n",
    "            return self.Node(value=leaf_value)\n",
    "        \n",
    "        feature, threshold, gain = self.__best_split(X, y)\n",
    "\n",
    "        if gain <= 0:\n",
    "            return self.Node(value=self.__most_common_label(y))\n",
    "        \n",
    "        X_left, y_left, X_right, y_right = split_dataset(X, y, feature, threshold)\n",
    "\n",
    "        # recursively find best split and build left and right subtree\n",
    "        left_child = self.__build_tree(X_left, y_left, depth+1)\n",
    "        right_child = self.__build_tree(X_right, y_right, depth+1)\n",
    "        \n",
    "        return self.Node(feature, threshold, left_child, right_child)\n",
    "    \n",
    "    def __predict_sample(self, x, node: Node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        \n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self.__predict_sample(x, node.left)\n",
    "        else:\n",
    "            return self.__predict_sample(x, node.right)\n",
    "        \n",
    "    def plot_tree(self):\n",
    "        G = nx.DiGraph()\n",
    "\n",
    "        def add_nodes_edges(node, parent=None, edge_label=\"\"):\n",
    "            if node is None:\n",
    "                return\n",
    "            \n",
    "            # label node\n",
    "            if node.value is not None:\n",
    "                label = f\"Leaf\\nClass={node.value}\"\n",
    "            else:\n",
    "                label = f\"X[{node.feature}] <= {node.threshold:.3f}\"\n",
    "\n",
    "            G.add_node(id(node), label=label)\n",
    "\n",
    "            # connect to parent\n",
    "            if parent is not None:\n",
    "                G.add_edge(id(parent), id(node), label=edge_label)\n",
    "\n",
    "            # recursively add children\n",
    "            if node.left:\n",
    "                add_nodes_edges(node.left, node, \"True\")\n",
    "            if node.right:\n",
    "                add_nodes_edges(node.right, node, \"False\")\n",
    "\n",
    "        add_nodes_edges(self.root)\n",
    "\n",
    "        pos = nx.nx_agraph.graphviz_layout(G, prog=\"dot\")\n",
    "\n",
    "        nx.draw(G, pos, with_labels=False, arrows=True)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.root = self.__build_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_sample(x, self.root) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d76c6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, max_depth=5, min_samples_split=2, feature_subsample_size=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.feature_subsample_size = feature_subsample_size\n",
    "        self.trees = []\n",
    "\n",
    "    def __bootstrap_sample(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        return X[indices], y[indices]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "\n",
    "        for _ in range(self.n_trees):\n",
    "            X_boot, y_boot = self.__bootstrap_sample(X,y)\n",
    "            tree = DecisionTree(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                feature_subsample_size=self.feature_subsample_size\n",
    "            )\n",
    "\n",
    "            tree.fit(X_boot, y_boot)\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        tree_predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        predictions = np.round(tree_predictions.mean(axis=0)).astype(int)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8eb5dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/diabetes.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd6f24af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (768, 8)\n",
      "Y shape: (768, 1)\n"
     ]
    }
   ],
   "source": [
    "# split data into X and Y\n",
    "X = data.drop(\"Outcome\", axis=1).values\n",
    "Y = data[\"Outcome\"].values.reshape(-1,1)\n",
    "\n",
    "print(f'X shape: {X.shape}\\nY shape: {Y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1b2965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and Y into train and test with stratification for unbalanced dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=Y)\n",
    "\n",
    "# create model object and fit train data\n",
    "RF = RandomForest(n_trees=20, max_depth=None, min_samples_split=5)\n",
    "RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a6c4ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3506\n",
      "Recall: 0.2814\n",
      "F1: 0.3122\n"
     ]
    }
   ],
   "source": [
    "# predict values on test data\n",
    "y_pred = RF.predict(X_test)\n",
    "\n",
    "# evaluate logistic regression model with precision, recall and f1 score\n",
    "eval_model(y_test, y_pred);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "courses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
